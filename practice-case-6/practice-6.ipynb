{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2021-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('fhv_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pyspark\\sql\\dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('fhvhv_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropOff_datetime',\n",
       " 'PUlocationID',\n",
       " 'DOlocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. How many taxi trips were there on February 15?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cara Pertama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|35709|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    count(pickup_datetime) as count\n",
    "FROM\n",
    "    fhvhv_data\n",
    "WHERE\n",
    "    DATE(pickup_datetime) = '2021-02-15' \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cara Kedua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|35709|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "select\n",
    "    count(pickup_datetime) as count\n",
    "from fhvhv_data\n",
    "where\n",
    "    pickup_datetime >= '2021-02-15' and pickup_datetime < '2021-02-16'\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cara Ketiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|35709|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(pickup_datetime) as count\n",
    "FROM \n",
    "    fhvhv_data\n",
    "WHERE\n",
    "    pickup_datetime BETWEEN '2021-02-15 00:00:00' AND '2021-02-15 23:59:59'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Find the longest trip for each day ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|pickup_date|          duration|\n",
      "+-----------+------------------+\n",
      "| 2021-02-01|           46290.0|\n",
      "| 2021-02-02|1390.7833333333333|\n",
      "| 2021-02-03|1246.1666666666667|\n",
      "| 2021-02-04| 40034.88333333333|\n",
      "| 2021-02-05|          110919.0|\n",
      "| 2021-02-06| 2752.633333333333|\n",
      "| 2021-02-07|1306.1166666666666|\n",
      "| 2021-02-08| 9424.916666666666|\n",
      "| 2021-02-09|1459.9833333333333|\n",
      "| 2021-02-10|1407.7166666666667|\n",
      "| 2021-02-11|3219.8166666666666|\n",
      "| 2021-02-12|            4344.0|\n",
      "| 2021-02-13| 8422.683333333332|\n",
      "| 2021-02-14|            1519.4|\n",
      "| 2021-02-15|          14670.15|\n",
      "| 2021-02-16|            4816.1|\n",
      "| 2021-02-17| 4284.783333333334|\n",
      "| 2021-02-18|2749.0333333333333|\n",
      "| 2021-02-19|           9012.15|\n",
      "| 2021-02-20|2701.4666666666667|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    DATE(pickup_datetime) AS pickup_date,\n",
    "    MAX((CAST(dropoff_datetime AS LONG) - CAST(pickup_datetime AS LONG)) / 60) AS duration\n",
    "FROM \n",
    "    fhvhv_data\n",
    "GROUP BY\n",
    "    1\n",
    "ORDER BY\n",
    "    1 ASC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Find Top 5 Most frequent `dispatching_base_num` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------------+\n",
      "|dispatching_base_num|count(dispatching_base_num)|\n",
      "+--------------------+---------------------------+\n",
      "|              B00856|                      35077|\n",
      "|              B01312|                      33089|\n",
      "|              B01145|                      31114|\n",
      "|              B02794|                      30397|\n",
      "|              B03016|                      29794|\n",
      "+--------------------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    dispatching_base_num, COUNT(dispatching_base_num)\n",
    "FROM\n",
    "    fhvhv_data\n",
    "GROUP BY\n",
    "    dispatching_base_num\n",
    "ORDER BY\n",
    "    COUNT(dispatching_base_num) DESC\n",
    "LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Find Top 5 Most common location pairs (PUlocationID and DOlocationID) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|pickup_dropoff_pair|count|\n",
      "+-------------------+-----+\n",
      "|        206.0/206.0| 2374|\n",
      "|        221.0/206.0| 2112|\n",
      "|        129.0/129.0| 1902|\n",
      "|            7.0/7.0| 1829|\n",
      "|        179.0/179.0| 1736|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    CONCAT(PULocationID, '/', DOLocationID) AS pickup_dropoff_pair,\n",
    "    COUNT(CONCAT(PULocationID, '/', DOLocationID)) AS count\n",
    "FROM \n",
    "    fhvhv_data\n",
    "GROUP BY\n",
    "    CONCAT(PULocationID, '/', DOLocationID)\n",
    "ORDER BY\n",
    "    count DESC\n",
    "LIMIT 5\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
